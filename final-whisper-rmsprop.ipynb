{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47e9b047-b3a7-4d11-b191-79b8045b0d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install --upgrade pip\n",
    "!pip install jiwer\n",
    "!pip install evaluate\n",
    "!pip install tensorboard\n",
    "!pip install datasets\n",
    "!pip install --upgrade transformers\n",
    "!pip install --upgrade torch\n",
    "!pip install --upgrade torchvision\n",
    "!pip install --upgrade torchaudio\n",
    "!pip install librosa\n",
    "!pip install numpy==2.1.0\n",
    "!pip install scipy==1.11.4\n",
    "!pip install librosa==0.10.1\n",
    "!pip install numba==0.58.1\n",
    "!pip install datasets>=2.14.0\n",
    "!pip install accelerate>=0.26.0\n",
    "!pip install typing_extensions --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68f3bc6c-2408-4334-8a39-1822c61e6d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install huggingface_hub --quiet\n",
    "\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e5d5639-bd3c-4324-8d87-b267c69a1a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting typing-extensions==4.12.2\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: typing-extensions\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.15.0\n",
      "    Uninstalling typing_extensions-4.15.0:\n",
      "      Successfully uninstalled typing_extensions-4.15.0\n",
      "Successfully installed typing-extensions-4.12.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mFiles removed: 36 (37.7 MB)\n"
     ]
    }
   ],
   "source": [
    "# Force upgrade typing_extensions to a version that supports 'TypeIs'\n",
    "!pip install --upgrade typing-extensions==4.12.2\n",
    "# Clear the internal pip cache to ensure no 'ghost' versions remain\n",
    "!pip cache purge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e25621e6-8ccf-45ef-8623-b08212981abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming pipeline ready. RAM usage should be minimal.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import WhisperFeatureExtractor, WhisperTokenizer\n",
    "\n",
    "# 1. Initialize dependencies\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small\")\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", language=\"Telugu\", task=\"transcribe\")\n",
    "\n",
    "# 2. DEFINE the function (to fix the NameError)\n",
    "def prepare_dataset(batch):\n",
    "    # Load audio data\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # Compute log-Mel spectrograms on-the-fly\n",
    "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "\n",
    "    # Encode transcription to label ids\n",
    "    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n",
    "    return batch\n",
    "\n",
    "# 3. Load with streaming=True\n",
    "ds = load_dataset(\"kaarthu2003/SlrCvVoicesTtsDataset\", streaming=True)\n",
    "\n",
    "# 4. Apply map (this is now INSTANT because it is lazy)\n",
    "train_data = ds[\"train\"].map(prepare_dataset)\n",
    "test_data = ds[\"validation\"].map(prepare_dataset)\n",
    "\n",
    "print(\"Streaming pipeline ready. RAM usage should be minimal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9d93d8c-e5a7-4dc4-b61b-6f70b3cbc148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchcodec in /usr/local/lib/python3.11/dist-packages (0.9.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torchcodec  # Add this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "016284bf-9845-4ddc-81b9-3098c2386031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease                         \n",
      "Hit:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease                 \n",
      "Hit:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease               \n",
      "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
      "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease   \n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 126 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!apt-get update && apt-get install -y ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3168761f-23ca-4b85-a63c-7eea173fdcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_few_words(example):\n",
    "    return len(example[\"sentence\"]) < 35  # or \"text\" if that's the field name\n",
    "\n",
    "filtered_test_data = test_data.filter(has_few_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef53cad4-0666-4c26-9482-55c33d25ef8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 longest sentences:\n",
      "1: (105 chars) మార్కెట్ యార్డులోని గోదాములో భద్రపరిచిన మిర్చి బస్తాలు అగ్ని ప్రమాదంలో కాలిపోవడంతో చాల నష్టం వాటిల్లింది.\n",
      "2: (105 chars) మార్కెట్ యార్డులోని గోదాములో భద్రపరిచిన మిర్చి బస్తాలు అగ్ని ప్రమాదంలో కాలిపోవడంతో చాల నష్టం వాటిల్లింది.\n",
      "3: (102 chars) సాయంకాలంలోపుగా రాళ్ళవంతెన దాదాపు నిర్మూలమైపోయింది కష్టపడి పనిచేసిన ప్రజలందరికీ బంగారునాణాలు, దొరికాయి.\n",
      "4: (102 chars) న్యాయపరమైన వివాదాలతో నిలిచిపోయిన నియామక ప్రక్రియ ముఖ్యమంత్రి చొరవతో ఎట్టకేలకు పరిష్కారానికి నోచుకుంది.\n",
      "5: (97 chars) రామరావణాయుద్ధం ముగిసింది అన్నారు ముగియటమేకాదు శ్రీరాముడు రామావతారం చాలించి కృష్ణావతారం ఎత్తేశాడు.\n",
      "6: (96 chars) ఆంధ్రప్రదేశ్ రాష్ట్ర మాజీ ముఖ్యమంత్రి నందమూరి తారక రామారావు రెండవ భార్య నందమూరి లక్ష్మీపార్వతి\\n\n",
      "7: (95 chars) వీరంతా, చోళరాజ్యం, మనచేతికి రావటానికి, ప్రాణాలోడ్డేవారే, అని, వినీతుడు, రాజుతో చెబుతూవుండేవాడు.\n",
      "8: (94 chars) రహస్యంగా నాటు తుపాకీలు తయారు చేస్తున్న కేంద్రంపై పోలీసులు దాడి చేసి కొంతమందిని అరెస్ట్ చేసారు.\n",
      "9: (94 chars) బ్రహ్మదత్తుడు దీర్గాయువు జాడ తీయలేకపోతిమే అని భయంతోనూ బెంగతోనూ మనస్తిమితంలేక కుమిలిపోజొచ్చాడు.\n",
      "10: (93 chars) క్రమంగా తూర్పు చాళుక్యుల రాజ్యం దక్షిణాన నెల్లూరు నుండి ఉత్తరాన శ్రీకాకుళం వరకు విస్తరించింది\n",
      "11: (93 chars) క్రమంగా తూర్పు చాళుక్యుల రాజ్యం దక్షిణాన నెల్లూరు నుండి ఉత్తరాన శ్రీకాకుళం వరకు విస్తరించింది\n",
      "12: (92 chars) ప్రముఖ తెలుగు సినీ దర్శకుడు కె విశ్వనాథ్ సిరివెన్నెల సినిమాకు పాటలు రాసే అవకాశం కల్పించారు\\n\n",
      "13: (91 chars) ఆమెను తనవద్ద ఉంచుకోటానికి పద్మావతి ఒప్పుకున్నది కార్యం సానుకూలమై యౌగంధరాయణుడు వెళ్లిపోయాడు.\n",
      "14: (90 chars) ఈ ప్రమాదం జరిగిన కొన్ని నెలల తర్వాత దీన్ని గురించి కొన్ని మూల గ్రంథాలు కూడా రాయడం జరిగింది\n",
      "15: (89 chars) మీరు కొత్తగా సృష్టించిన టంగుటూరి ప్రకాశం పేజీ లోని విషయాన్ని అనువదించి పై పేజీలో పెట్టండి\n",
      "16: (88 chars) ఈ ప్రమాదం జరిగిన కొన్ని నెలల తర్వాత దీని గురించి కొన్ని మూల గ్రంథాలు కూడా రాయడం జరిగింది\n",
      "17: (86 chars) మాధవుడనే క్షత్రియకుమారుడు చాలా దూరప్రాంతన్నుంచి తమ దర్శనార్ధం వచ్చాడు అని కబురుచేశాడు.\n",
      "18: (85 chars) శ్రీకాకుళం జిల్లా భారత దేశము లోని ఆంధ్ర ప్రదేశ్ రాష్ట్రం లో ఈశాన్య సరిహద్దు లో ఉన్నది\n",
      "19: (84 chars) ఆడితప్పను గనకనే, దుర్మార్గుడైన ఆ బ్రాహ్మణుడికి, సాయం చేస్తున్నాను, అన్నాడు, కేసటుడు.\n",
      "20: (83 chars) రాజు పెద్దమ్మ చెప్పినదాంట్లో సత్యమున్నదని గ్రహించి ఆమె తెలివితేటలకు ఆశ్చర్యపడ్డాడు.\n",
      "21: (81 chars) ఒకప్పుడు పురుషోత్తముడు దేశంలోగల దివ్య క్షేత్రాలన్నీ దర్శించుకురావాలీ అనుకున్నాడు.\n",
      "22: (81 chars) అందుకు అనుగుణంగా మీరు మీ గురించి వ్రాసిన సమాచారాన్ని మీ సభ్యుని పేజీలోకి మార్చాను\n",
      "23: (80 chars) కుత్బుల్లాపూర్ ఆంధ్ర ప్రదేశ్ రాష్ట్రంలోని రంగారెడ్డి జిల్లాకు చెందిన ఒక మండలము..\n",
      "24: (79 chars) ఈ గ్రామము సినీ దర్శకుడు సంగీత దర్శకుడు అయిన ఎస్.వి.కృష్ణారెడ్డి యొక్క స్వస్థలము\n",
      "25: (78 chars) తాండ్ర సారంగాపూర్ అదిలాబాదు జిల్లాలోని సారంగాపూర్ మండలానికి చెందిన ఒక గ్రామము.\n",
      "26: (78 chars) బజార్‌హథ్నూర్‌ ఆంధ్ర ప్రదేశ్ రాష్ట్రములోని అదిలాబాదు జిల్లాకు చెందిన ఒక మండలము\n",
      "27: (78 chars) మరి కొంత దూరంలో ఉన్న సుబ్రహ్మణ్య స్వామి కొండపై కూడా ఉత్సవాలు ఘనంగా జరుగుతాయి\\n\n",
      "28: (78 chars) అవ్వా, నిదరొస్తుంది, మాకు పడుకునేటందుకు చోటు చూపించు, అన్నాడు సర్దారు తమ్ముడు.\n",
      "29: (78 chars) నందమూరి అక్కినేని తొలిసారి కలసి నటించిన సుబ్బారావు తొలి చిత్రం పల్లెటూరి పిల్ల\n",
      "30: (76 chars) మరి కొంత దూరంలో ఉన్న సుబ్రహ్మణ్య స్వామి కొండపై కూడా ఉత్సవాలు ఘనంగా జరుగుతాయి\n"
     ]
    }
   ],
   "source": [
    "# Print the 30 longest sentences in test_data\n",
    "sorted_sentences = sorted(test_data, key=lambda x: len(x[\"sentence\"]), reverse=True)\n",
    "print(\"30 longest sentences:\")\n",
    "for i, example in enumerate(sorted_sentences[:30]):\n",
    "    print(f\"{i+1}: ({len(example['sentence'])} chars) {example['sentence']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5eb34a8d-0fdb-4123-9cb3-3b69158f65c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying training samples...\n",
      "Sample 1 audio shape: (80, 3000)\n",
      "Sample 1 label length: 39\n",
      "Sample 2 audio shape: (80, 3000)\n",
      "Sample 2 label length: 72\n",
      "\n",
      "Dataset is streaming correctly. Total size is approximately 15,811 (from metadata).\n"
     ]
    }
   ],
   "source": [
    "# Instead of len(), just verify the first 2 examples to see if they load\n",
    "print(\"Verifying training samples...\")\n",
    "for i, example in enumerate(train_data.take(2)):\n",
    "    print(f\"Sample {i+1} audio shape: {example['input_features'].shape}\")\n",
    "    print(f\"Sample {i+1} label length: {len(example['labels'])}\")\n",
    "\n",
    "print(\"\\nDataset is streaming correctly. Total size is approximately 15,811 (from metadata).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "094a076a-1a9a-42a4-a7eb-582d9ba27647",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = filtered_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b66dda78-91da-4492-a955-bfa914e36dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "telugu_special_unwanted_characters = [\n",
    "    'ౄ',  # Vocalic RR\n",
    "    'ౢ',  # Vocalic L\n",
    "    'ౣ',  # Vocalic LL\n",
    "    'ౠ',  # Long Vocalic RR\n",
    "    'ఽ',  # Avagraha\n",
    "    '౦', '౧', '౨', '౩', '౪', '౫', '౬', '౭', '౮', '౯',  # Telugu digits\n",
    "    'ఀ',  # Telugu Sign Combining Candrabindu Above\n",
    "    'ౘ',  # Letter TTHA\n",
    "    'ౙ',  # Letter DDA\n",
    "    'ౚ',  # Letter RHA\n",
    "    '౷',  # Vedic Tone\n",
    "    '‘', '’', '“', '”', '%', '.', ';', '-', ',', '/', '\\\\', '_', '&',  # Common punctuation\n",
    "    'G', 'P', 'S', 'e', 'l', 'n', 'r', 't', '\\u200c' #Unwanted in the dataset\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edc8141c-0e22-42cf-9f11-3c1cd23210c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns: None\n",
      "\n",
      "Sample row data:\n",
      "<datasets.iterable_dataset.IterableColumn object at 0x79e60591f650>\n"
     ]
    }
   ],
   "source": [
    "# List all column names to find the correct text keyword\n",
    "print(f\"Available columns: {train_data.column_names}\")\n",
    "\n",
    "# Alternatively, peek at one full row to see the data structure\n",
    "print(\"\\nSample row data:\")\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1f69abf-8a80-4a54-b554-c18050cdeb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "chars_to_remove_regex = f'[{re.escape(\"\".join(telugu_special_unwanted_characters))}]'\n",
    "\n",
    "def remove_special_characters(batch):\n",
    "    batch[\"sentence\"] = re.sub(chars_to_remove_regex, '', batch[\"sentence\"])\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a80cc55c-828e-4a16-8470-2bd130e65c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.map(remove_special_characters)\n",
    "test_data = test_data.map(remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "452eda67-2b36-4ac1-914a-70c70a80a80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_name = \"whisper-train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc989b44-f396-439c-989d-03f6264e3033",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperFeatureExtractor\n",
    "\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2d9e3fd-a16d-4ecf-917e-1d2cb88bbd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperTokenizer\n",
    "\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", language=\"Telugu\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54499e22-b36c-49dd-a2a5-2289f740cb39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "244ecf34669242debd37e5774d4412e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/anvitamanne/whisper-train/commit/a2414d01acc8816d4ea7dd7430c06a9a5c5d3a40', commit_message='Upload tokenizer', commit_description='', oid='a2414d01acc8816d4ea7dd7430c06a9a5c5d3a40', pr_url=None, repo_url=RepoUrl('https://huggingface.co/anvitamanne/whisper-train', endpoint='https://huggingface.co', repo_type='model', repo_id='anvitamanne/whisper-train'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub(repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88979258-611f-489e-aaa3-4ab17b80c044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:    దాగుడుమూతల ఆట వల్ల\n",
      "Decoded:  దాగుడుమూతల ఆట వల్ల\n"
     ]
    }
   ],
   "source": [
    "# 1. Use 'next' and 'iter' to pull the first available example from the stream\n",
    "example = next(iter(train_data))\n",
    "input_str = example[\"sentence\"]\n",
    "\n",
    "# 2. Tokenize the string (this will now work correctly)\n",
    "labels = tokenizer(input_str).input_ids\n",
    "decoded_str = tokenizer.decode(labels, skip_special_tokens=True)\n",
    "\n",
    "print(f\"Input:    {input_str}\")\n",
    "print(f\"Decoded:  {decoded_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02fc1419-4a67-4472-88d1-65cd363b8b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperProcessor\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"Telugu\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8422c194-efd8-4fdc-bc06-88853eb4c99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<datasets.iterable_dataset.IterableColumn object at 0x79e44a869ad0>\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "533fb755-ffcf-4bba-aa43-f1eaf52ea56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling and cleaning pipeline is active in the stream.\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import re\n",
    "\n",
    "def prepare_dataset_safe(batch):\n",
    "    # 1. Clean the text (Fixes the special characters issue)\n",
    "    batch[\"sentence\"] = re.sub(chars_to_remove_regex, '', batch[\"sentence\"])\n",
    "    \n",
    "    # 2. Handle Resampling Manually (Fixes the cast_column error)\n",
    "    audio = batch[\"audio\"]\n",
    "    if audio[\"sampling_rate\"] != 16000:\n",
    "        # Resample the 1D array to exactly 16000Hz as Whisper requires\n",
    "        audio[\"array\"] = librosa.resample(\n",
    "            audio[\"array\"], \n",
    "            orig_sr=audio[\"sampling_rate\"], \n",
    "            target_sr=16000\n",
    "        )\n",
    "        audio[\"sampling_rate\"] = 16000\n",
    "\n",
    "    # 3. Extract Whisper Features\n",
    "    batch[\"input_features\"] = feature_extractor(\n",
    "        audio[\"array\"], \n",
    "        sampling_rate=16000\n",
    "    ).input_features[0]\n",
    "    \n",
    "    # 4. Tokenize labels\n",
    "    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n",
    "    return batch\n",
    "\n",
    "# Apply to your streaming data (This will be instant and RAM-safe)\n",
    "train_data = train_data.map(prepare_dataset_safe)\n",
    "test_data = test_data.map(prepare_dataset_safe)\n",
    "\n",
    "print(\"Resampling and cleaning pipeline is active in the stream.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28bab85e-07bb-4a17-8001-a2408fd91ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<datasets.iterable_dataset.IterableColumn object at 0x79e44bda5350>\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06fc1e0f-78e3-4a34-af18-f4bb011885f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the processed datasets cache (where the error occurred)\n",
    "!rm -rf ~/.cache/huggingface/datasets/*\n",
    "\n",
    "# Optional: Clear the downloaded model/dataset files if you need more room\n",
    "!rm -rf ~/.cache/huggingface/hub/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3f2fed1-517b-4d44-a5dd-95c96d946f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Create a folder in workspace for the cache\n",
    "os.makedirs(\"/workspace/hf_cache\", exist_ok=True)\n",
    "\n",
    "# Point Hugging Face to use the larger disk space\n",
    "os.environ[\"HF_HOME\"] = \"/workspace/hf_cache\"\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"/workspace/hf_cache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55992551-f334-4ee9-9a85-35490ecdadb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import re\n",
    "\n",
    "def prepare_dataset(batch):\n",
    "    # 1. Clean the text (Fixes the special characters issue)\n",
    "    # This ensures your 'labels' don't contain unwanted Telugu characters\n",
    "    batch[\"sentence\"] = re.sub(chars_to_remove_regex, '', batch[\"sentence\"])\n",
    "    \n",
    "    # 2. Manual Resampling (Fixes the cast_column error)\n",
    "    # Whisper requires exactly 16,000Hz to understand the audio\n",
    "    audio = batch[\"audio\"]\n",
    "    if audio[\"sampling_rate\"] != 16000:\n",
    "        audio[\"array\"] = librosa.resample(\n",
    "            audio[\"array\"], \n",
    "            orig_sr=audio[\"sampling_rate\"], \n",
    "            target_sr=16000\n",
    "        )\n",
    "        audio[\"sampling_rate\"] = 16000\n",
    "\n",
    "    # 3. Extract Whisper Features (spectrograms)\n",
    "    batch[\"input_features\"] = feature_extractor(\n",
    "        audio[\"array\"], \n",
    "        sampling_rate=16000\n",
    "    ).input_features[0]\n",
    "    \n",
    "    # 4. Tokenize labels\n",
    "    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7c6d4ff-1fa3-4833-ad0d-8037ee926863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming pipeline updated. Map is now lazy and RAM-safe.\n"
     ]
    }
   ],
   "source": [
    "# SAFE: No remove_columns or keep_in_memory needed for streaming\n",
    "train_data = ds[\"train\"].map(prepare_dataset)\n",
    "test_data = ds[\"validation\"].map(prepare_dataset)\n",
    "\n",
    "print(\"Streaming pipeline updated. Map is now lazy and RAM-safe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5612ab87-5374-427f-b938-c02219d3334c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20598ed0df34b2a9efbe2cd7bbeaf58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d942b5046eaf49ed87e78e8c23abdae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/967M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5df502d3207041f2b141b8ca299e5e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b3fe846-3da6-421e-9e4c-59a3332d0234",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.generation_config.language = \"telugu\"\n",
    "model.generation_config.task = \"transcribe\"\n",
    "\n",
    "model.generation_config.forced_decoder_ids = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad12934e-f351-43d4-bf7c-8604782ab614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "    decoder_start_token_id: int\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.decoder_start_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea74f73c-3c3e-43e2-b27a-6f8c8cbd010f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n",
    "    processor=processor,\n",
    "    decoder_start_token_id=model.config.decoder_start_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ba2a2651-62fe-470a-898b-4ea9c6b27251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c98a47ce93142758c5966a1bea67f91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd58c15618a45c89d1df7e93812e060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "wer_metric = evaluate.load(\"wer\")\n",
    "cer_metric = evaluate.load(\"cer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "911d7171-23a8-4623-94bd-6b6e31f88f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "    cer = cer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer, \"cer\": cer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "59a5cde8-d314-4011-bbac-b7e617631dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3ff45ec2-0af0-409c-b4e2-e254a463ee1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import torch\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Check GPU memory status\n",
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3badc452-8972-4b1a-9a9c-de2c8314ae6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update complete. Model Use Cache is now: False\n"
     ]
    }
   ],
   "source": [
    "# 1. FIX: Disable cache to prevent the \"backward through graph\" RuntimeError\n",
    "model.config.use_cache = False\n",
    "\n",
    "# 2. OPTIONAL BUT RECOMMENDED: Clear suppress_tokens\n",
    "# This ensures the model doesn't accidentally block useful Telugu characters\n",
    "model.config.suppress_tokens = []\n",
    "\n",
    "print(f\"Update complete. Model Use Cache is now: {model.config.use_cache}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "523962db-96a6-40f7-822b-1a3faab2c39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Use Cache: False (Should be False)\n",
      "Forced Decoder IDs: [[1, 50259], [2, 50359], [3, 50363]]\n",
      "Tokenizer Language: Telugu\n",
      "GPU detected: NVIDIA A40\n"
     ]
    }
   ],
   "source": [
    "# 1. Check if Gradient Checkpointing cache is disabled\n",
    "print(f\"Model Use Cache: {model.config.use_cache} (Should be False)\")\n",
    "\n",
    "# 2. Check if the model is locked to Telugu\n",
    "print(f\"Forced Decoder IDs: {model.config.forced_decoder_ids}\")\n",
    "\n",
    "# 3. Check the Processor's language\n",
    "# This ensures the tokenizer knows to use Telugu characters\n",
    "print(f\"Tokenizer Language: {processor.tokenizer.language}\")\n",
    "\n",
    "# 4. Verify GPU Availability\n",
    "import torch\n",
    "print(f\"GPU detected: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'No GPU found'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5838034e-c628-4b76-aea3-5eaa940bbeca",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No valid checkpoint found in output directory (whisper-train)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 42\u001b[0m\n\u001b[1;32m     30\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Seq2SeqTrainer(\n\u001b[1;32m     31\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m     32\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mprocessor\u001b[38;5;241m.\u001b[39mfeature_extractor,\n\u001b[1;32m     38\u001b[0m )\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# 4. Resume from your existing checkpoint\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# It will jump to step 1000 and continue toward the 19760 goal\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py:2293\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2291\u001b[0m     resume_from_checkpoint \u001b[38;5;241m=\u001b[39m get_last_checkpoint(args\u001b[38;5;241m.\u001b[39moutput_dir)\n\u001b[1;32m   2292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resume_from_checkpoint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2293\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo valid checkpoint found in output directory (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resume_from_checkpoint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_sagemaker_mp_enabled() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_deepspeed_enabled \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_fsdp_enabled:\n",
      "\u001b[0;31mValueError\u001b[0m: No valid checkpoint found in output directory (whisper-train)"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "import torch\n",
    "\n",
    "# 1. Essential model-level fix for the backward-pass error\n",
    "model.config.use_cache = False  \n",
    "\n",
    "# 2. Updated Training Arguments for exactly 20 Epochs\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=repo_name,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=8,      # 1. Lower eval batch size (Safety)\n",
    "    eval_accumulation_steps=1,         # 2. IMMEDIATELY move results to CPU RAM\n",
    "    predict_with_generate=True,        # 3. Required for WER calculation\n",
    "    generation_max_length=225,         # 4. Prevents runaway memory usage\n",
    "    learning_rate=1e-5,\n",
    "    optim=\"rmsprop\",\n",
    "    max_steps=19760,                   # Your 20-epoch goal\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    "    save_steps=1000,\n",
    "    save_total_limit=2,\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
    "    fp16=True,\n",
    "    fp16_full_eval=True, # Forces evaluation to also use half-precision\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "# 3. Re-initialize trainer with the stream\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=test_data,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")\n",
    "\n",
    "# 4. Resume from your existing checkpoint\n",
    "# It will jump to step 1000 and continue toward the 19760 goal\n",
    "trainer.train(resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "83937168-855f-4c86-b607-cda873c7df80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access './checkpoint-*': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls -d ./checkpoint-*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9beee2e8-a78c-4733-ad13-6c81265f0b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Clear any 'ghost' memory from the crash\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9e1db2d4-f9c0-48c8-ad08-c9d2bcb0cf29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint found. Starting training from scratch.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19760' max='19760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19760/19760 7:32:56, Epoch 19/9223372036854775807]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "      <th>Cer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.123500</td>\n",
       "      <td>0.117702</td>\n",
       "      <td>0.347799</td>\n",
       "      <td>0.088205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.064200</td>\n",
       "      <td>0.133981</td>\n",
       "      <td>0.339772</td>\n",
       "      <td>0.088789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.033700</td>\n",
       "      <td>0.153300</td>\n",
       "      <td>0.336511</td>\n",
       "      <td>0.084489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>0.166429</td>\n",
       "      <td>0.326226</td>\n",
       "      <td>0.084118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.012600</td>\n",
       "      <td>0.172460</td>\n",
       "      <td>0.316694</td>\n",
       "      <td>0.081234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>0.194955</td>\n",
       "      <td>0.332748</td>\n",
       "      <td>0.084118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.185532</td>\n",
       "      <td>0.303399</td>\n",
       "      <td>0.080703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.193177</td>\n",
       "      <td>0.306033</td>\n",
       "      <td>0.079747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.195440</td>\n",
       "      <td>0.301518</td>\n",
       "      <td>0.078810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.201081</td>\n",
       "      <td>0.307036</td>\n",
       "      <td>0.080030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.197619</td>\n",
       "      <td>0.291735</td>\n",
       "      <td>0.077571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.212201</td>\n",
       "      <td>0.302772</td>\n",
       "      <td>0.079163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.200979</td>\n",
       "      <td>0.296877</td>\n",
       "      <td>0.077889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.218651</td>\n",
       "      <td>0.297504</td>\n",
       "      <td>0.078403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.224896</td>\n",
       "      <td>0.295623</td>\n",
       "      <td>0.076722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.226342</td>\n",
       "      <td>0.291609</td>\n",
       "      <td>0.076138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.231392</td>\n",
       "      <td>0.289101</td>\n",
       "      <td>0.076279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.234629</td>\n",
       "      <td>0.288599</td>\n",
       "      <td>0.075642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238378</td>\n",
       "      <td>0.286969</td>\n",
       "      <td>0.074881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:3918: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "\n",
    "# 1. Manually find the last checkpoint in your output directory\n",
    "last_checkpoint = get_last_checkpoint(training_args.output_dir)\n",
    "\n",
    "if last_checkpoint is not None:\n",
    "    print(f\"Checkpoint found! Resuming from: {last_checkpoint}\")\n",
    "    trainer.train(resume_from_checkpoint=last_checkpoint)\n",
    "else:\n",
    "    # If no checkpoint is found, check if it's just in the current directory\n",
    "    if os.path.exists(\"./checkpoint-1000\"):\n",
    "        print(\"Found checkpoint-1000 in current directory. Resuming...\")\n",
    "        trainer.train(resume_from_checkpoint=\"./checkpoint-1000\")\n",
    "    else:\n",
    "        print(\"No checkpoint found. Starting training from scratch.\")\n",
    "        trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9b284167-72cc-4c72-984b-b84e57b087a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63a5e98d511d4425a00f95d846dfdaad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a11f340ca342199bb0ef5392ac3842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/anvitamanne/whisper-train/commit/33b7b05b39f21efe40723e50330decce73e564f1', commit_message='End of training', commit_description='', oid='33b7b05b39f21efe40723e50330decce73e564f1', pr_url=None, repo_url=RepoUrl('https://huggingface.co/anvitamanne/whisper-train', endpoint='https://huggingface.co', repo_type='model', repo_id='anvitamanne/whisper-train'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "087a0ec4-5e9d-4635-a003-562e005dd405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa04d22baf840a78451fc71d767862b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad6a6d5e0e4342bf97302b26fa8a3057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/967M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b56a639b98534507af987dccd7aa3d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ffbe06752a4d23912ae9724195b297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/356 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50675db75f7949c6b30c0449687fa57c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b7e5245366e42acabfdbadaee5f1831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d45adb78845d486f817a42573f86965b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2224263f6e4e4b2aaf51c4a6e2b1e0de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93cf0f5c6cdc4c749f575a4162d950db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ebe299490d9446b8f24b8004519a137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import WhisperForConditionalGeneration, WhisperProcessor\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"anvitamanne/whisper-train\")\n",
    "processor = WhisperProcessor.from_pretrained(\"anvitamanne/whisper-train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9b8cfc70-3f72-4e4d-a246-b1ebcc83bd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<datasets.iterable_dataset.IterableColumn object at 0x79d15877cfd0>\n"
     ]
    }
   ],
   "source": [
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8318ccb8-caa2-4dd0-a856-483429cb9b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bba2293b7624e419653b6f8c5262354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Word Error Rate (WER): 28.67%\n",
      "Final Character Error Rate (CER): 7.55%\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "# 1. Properly load the WER and CER metrics\n",
    "wer_metric = evaluate.load(\"wer\")\n",
    "cer_metric = evaluate.load(\"cer\")\n",
    "\n",
    "# 2. Compute using the correct variable names from your loop\n",
    "# Multiplying by 100 to show as a percentage (%)\n",
    "final_wer = 100 * wer_metric.compute(predictions=predictions, references=references)\n",
    "final_cer = 100 * cer_metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "print(f\"Final Word Error Rate (WER): {final_wer:.2f}%\")\n",
    "print(f\"Final Character Error Rate (CER): {final_cer:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c3fe82db-f516-41a3-847c-07d6da0d5275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating transcriptions...\n",
      "\n",
      "Word Error Rate (WER): 28.67%\n",
      "Character Error Rate (CER): 7.55%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import evaluate\n",
    "\n",
    "# 1. Define the metrics properly to fix the NameError\n",
    "wer_metric = evaluate.load(\"wer\")\n",
    "cer_metric = evaluate.load(\"cer\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval() # Set model to evaluation mode\n",
    "\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "# 2. Iterate through test_data (Safe for Streaming datasets)\n",
    "print(\"Generating transcriptions...\")\n",
    "with torch.no_grad(): # Saves memory by not calculating gradients\n",
    "    for i, example in enumerate(test_data):\n",
    "        # Optional: Limit to 100 samples if your test set is very large\n",
    "        # if i >= 100: break \n",
    "\n",
    "        input_features = torch.tensor(example[\"input_features\"]).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Generate predictions\n",
    "        predicted_ids = model.generate(input_features)\n",
    "        predicted_text = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "        # Decode ground truth labels\n",
    "        label = example[\"labels\"]\n",
    "        if isinstance(label, int):\n",
    "            label = [label]\n",
    "        \n",
    "        # Filter out -100 (padding) tokens if they exist\n",
    "        label = [l for l in label if l != -100]\n",
    "        reference_text = processor.batch_decode([label], skip_special_tokens=True)[0]\n",
    "\n",
    "        predictions.append(predicted_text)\n",
    "        references.append(reference_text)\n",
    "\n",
    "# 3. Compute final percentages\n",
    "final_wer = 100 * wer_metric.compute(predictions=predictions, references=references)\n",
    "final_cer = 100 * cer_metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "print(f\"\\nWord Error Rate (WER): {final_wer:.2f}%\")\n",
    "print(f\"Character Error Rate (CER): {final_cer:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00559348-53d8-4ee0-a937-dd9e1109b829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de073f6-bc5e-4735-a3d1-ff2314240086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d990012-d1b2-4731-a75a-6ac629d44578",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea80e7b-52f0-48a2-b049-e30355d7eef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f6c523-c3ac-4601-b5e7-b4c6c58b16a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743ee287-80e1-4e0d-8fdc-5a72a35cbe90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7457d8fa-6336-413c-b032-93f5ecc1eded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaaf18f-cf32-430b-8469-b8d7e64bdb4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474ef368-8810-40d4-a5bb-e279d9aafbd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b09475b-87aa-4011-b73d-8e7380e5c8f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fa0388-47fb-4f49-bc76-686e7bf7307b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a76457-b300-4f1d-8b13-cc0df0884ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c675d9-d2e2-4a7c-b1ae-e55d5b43ece2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79602f5-1a02-4764-b428-adc45a1a1cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d862ab4c-dce9-4e54-bc82-9fe7a5fe24e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df93cb6c-ccce-45c9-a6b9-2cdbe7c1f977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d992451-9903-4e9f-a47e-9bb1c1c35e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0e57bf-f515-463d-b4c9-b945ebea4ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5e5b04-c821-489d-8a86-4779af39c4eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dc0e31-df45-4a0f-9d32-a297e8136ead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4307051-c8da-4e04-930e-8a85b3b77842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6c0d37-747c-41df-a30d-8cf431d07ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efed07c2-1fad-49df-b1f5-74a66a003241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4537f958-d3bf-4ccd-9cb2-968c6746377c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6cb93f-7431-427d-9a90-643971bd6b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21c766d-9d2a-47f6-84bb-e94e88ee7f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39e3d42-07ad-4dc6-b0b9-e0d8ba6d4531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1400368-c390-4b47-8def-dc180966e49f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec2980d-22e5-4301-83fa-141bafaacc71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ce40d2-3806-4fa6-a179-176ae69a6e37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e5dc8f-a111-4fe4-9b5a-add6c4601976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bd48a3-6940-465c-ad1e-f48afa223cdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
